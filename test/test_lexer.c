#include "common.h"
#include "lexer.h"

tgc_t gc;

void _main(void);

int main(void)
{
	volatile void *dummy;
	tgc_start(&gc, &dummy);
	_main();
	tgc_stop(&gc);
}

void _main(void)
{
	struct lexer lexer;
	lexer_init(&lexer, "50", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "50") == 0);
	assert(lexer.current_token.type == TOKEN_NUMBER);

	lexer_init(&lexer, "   19.271", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "19.271") == 0);
	assert(lexer.current_token.type == TOKEN_NUMBER);

	lexer_init(&lexer, "19.271.", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "19.271.") == 0);
	assert(lexer.current_token.type == TOKEN_ERROR);

	lexer_init(&lexer, "\"string\"   ", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "\"string\"") == 0);
	assert(lexer.current_token.type == TOKEN_STRING);

	lexer_init(&lexer, "  '  ", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "'") == 0);
	assert(lexer.current_token.type == TOKEN_QUOTE);

	lexer_init(&lexer, " (   ", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "(") == 0);
	assert(lexer.current_token.type == TOKEN_LPAREN);
	assert(lexer.input.line == 1);

        lexer_init(&lexer, "  \n)", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, ")") == 0);
	assert(lexer.current_token.type == TOKEN_RPAREN);
	assert(lexer.input.line == 2);

	lexer_init(&lexer, " ", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "") == 0);
	assert(lexer.current_token.type == TOKEN_EOF);

	lexer_init(&lexer, "symbol", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "symbol") == 0);
	assert(lexer.current_token.type == TOKEN_SYMBOL);

	lexer_init(&lexer, "symbol 10", 0);
	lexer_scan(&lexer);
	assert(strcmp(lexer.current_token.lexeme, "symbol") == 0);
	assert(lexer.current_token.type == TOKEN_SYMBOL);
	struct token t = lexer_peek(&lexer);
	assert(strcmp(t.lexeme, "10") == 0);
	assert(t.type == TOKEN_NUMBER);
	assert(strcmp(lexer.current_token.lexeme, "symbol") == 0);
	assert(lexer.current_token.type == TOKEN_SYMBOL);

	char *str = "(define (factorial n)\
  (if (= n 0)\
      1\
      (* n (factorial (- n 1)))))\
\
(define (map f lst)\
  (if (null? lst)\
      '()\
      (cons (f (car lst)) (map f (cdr lst)))))\
\
(define (filter pred lst)\
  (cond ((null? lst) '())\
        ((pred (car lst)) (cons (car lst) (filter pred (cdr lst))))\
        (else (filter pred (cdr lst)))))\
\
\
(define (fib n)\
  (if (< n 2)\
      n\
      (+ (fib (- n 1)) (fib (- n 2)))))\
\
(define (quicksort lst)\
  (if (null? lst)\
      '()\
      (let ((pivot (car lst))\
            (rest (cdr lst)))\
        (append (quicksort (filter (lambda (x) (< x pivot)) rest))\
                (cons pivot (quicksort (filter (lambda (x) (>= x pivot)) rest)))))))\
\
(display (factorial 5))\
(display (map (lambda (x) (* x x)) '(1 2 3 4 5)))\
(display (filter (lambda (x) (odd? x)) '(1 2 3 4 5)))\
(display (fib 10))\
(display (quicksort '(5 1 4 2 8)))";
	
	Token tokens[] = {
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_NUMBER,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_QUOTE,
		TOKEN_LPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_QUOTE,
		TOKEN_LPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_QUOTE,
		TOKEN_LPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_QUOTE,
		TOKEN_LPAREN,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_SYMBOL,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_QUOTE,
		TOKEN_LPAREN,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_LPAREN,
		TOKEN_SYMBOL,
		TOKEN_QUOTE,
		TOKEN_LPAREN,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_NUMBER,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_RPAREN,
		TOKEN_EOF
	};
	char *lexemes[] = {
		"(",
		"define",
		"(",
		"factorial",
		"n",
		")",
		"(",
		"if",
		"(",
		"=",
		"n",
		"0",
		")",
		"1",
		"(",
		"*",
		"n",
		"(",
		"factorial",
		"(",
		"-",
		"n",
		"1",
		")",
		")",
		")",
		")",
		")",
		"(",
		"define",
		"(",
		"map",
		"f",
		"lst",
		")",
		"(",
		"if",
		"(",
		"null?",
		"lst",
		")",
		"'",
		"(",
		")",
		"(",
		"cons",
		"(",
		"f",
		"(",
		"car",
		"lst",
		")",
		")",
		"(",
		"map",
		"f",
		"(",
		"cdr",
		"lst",
		")",
		")",
		")",
		")",
		")",
		"(",
		"define",
		"(",
		"filter",
		"pred",
		"lst",
		")",
		"(",
		"cond",
		"(",
		"(",
		"null?",
		"lst",
		")",
		"'",
		"(",
		")",
		")",
		"(",
		"(",
		"pred",
		"(",
		"car",
		"lst",
		")",
		")",
		"(",
		"cons",
		"(",
		"car",
		"lst",
		")",
		"(",
		"filter",
		"pred",
		"(",
		"cdr",
		"lst",
		")",
		")",
		")",
		")",
		"(",
		"else",
		"(",
		"filter",
		"pred",
		"(",
		"cdr",
		"lst",
		")",
		")",
		")",
		")",
		")",
		"(",
		"define",
		"(",
		"fib",
		"n",
		")",
		"(",
		"if",
		"(",
		"<",
		"n",
		"2",
		")",
		"n",
		"(",
		"+",
		"(",
		"fib",
		"(",
		"-",
		"n",
		"1",
		")",
		")",
		"(",
		"fib",
		"(",
		"-",
		"n",
		"2",
		")",
		")",
		")",
		")",
		")",
		"(",
		"define",
		"(",
		"quicksort",
		"lst",
		")",
		"(",
		"if",
		"(",
		"null?",
		"lst",
		")",
		"'",
		"(",
		")",
		"(",
		"let",
		"(",
		"(",
		"pivot",
		"(",
		"car",
		"lst",
		")",
		")",
		"(",
		"rest",
		"(",
		"cdr",
		"lst",
		")",
		")",
		")",
		"(",
		"append",
		"(",
		"quicksort",
		"(",
		"filter",
		"(",
		"lambda",
		"(",
		"x",
		")",
		"(",
		"<",
		"x",
		"pivot",
		")",
		")",
		"rest",
		")",
		")",
		"(",
		"cons",
		"pivot",
		"(",
		"quicksort",
		"(",
		"filter",
		"(",
		"lambda",
		"(",
		"x",
		")",
		"(",
		">=",
		"x",
		"pivot",
		")",
		")",
		"rest",
		")",
		")",
		")",
		")",
		")",
		")",
		")",
		"(",
		"display",
		"(",
		"factorial",
		"5",
		")",
		")",
		"(",
		"display",
		"(",
		"map",
		"(",
		"lambda",
		"(",
		"x",
		")",
		"(",
		"*",
		"x",
		"x",
		")",
		")",
		"'",
		"(",
		"1",
		"2",
		"3",
		"4",
		"5",
		")",
		")",
		")",
		"(",
		"display",
		"(",
		"filter",
		"(",
		"lambda",
		"(",
		"x",
		")",
		"(",
		"odd?",
		"x",
		")",
		")",
		"'",
		"(",
		"1",
		"2",
		"3",
		"4",
		"5",
		")",
		")",
		")",
		"(",
		"display",
		"(",
		"fib",
		"10",
		")",
		")",
		"(",
		"display",
		"(",
		"quicksort",
		"'",
		"(",
		"5",
		"1",
		"4",
		"2",
		"8",
		")",
		")",
		")",
		""
	};
	lexer_init(&lexer, str, 0);
	for (int i = 0; i < 311; i++) {
		struct token t = lexer_scan(&lexer);
		assert(t.type == tokens[i]);
		assert(strcmp(t.lexeme, lexemes[i]) == 0);
	}
}
